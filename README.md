A summary of coursera course about sre

# SRE vs DevOPS
# CRE (Customer Reliability Engineering)
CRE's Three Reliability Principes
- Reliability is the most important feature
- User, not monitoring, decide reliability
- Well-engineered...
# SLO (Service Level Objects)
>  It's totally possible to build a super reliable system that has no features and never changes, but it's hard to make any money by doing that. For most businesses, there is a constant pressure for new features to drive user acquisition and revenue growth, and balancing this demand with the need to maintain system reliability is quite challenging. Targeting a specific level of reliability is key to establishing that balance. We call these targets Service Level Objectives or SLOs. The main question SLOs can help executives and product teams answer is if reliability is a feature, how do you prioritize it versus other features? Setting a target for system reliability and communicating that target widely allows all parts of your organization to determine independently whether or not the service is reliable enough. Acknowledging that a specific quantity of unreliability is acceptable provides a budget for failure that can be spent on developing and launching new features. The remaining budget provides a signal to feed in your planning cycles to ensure work to improve reliability is prioritized. The incentives for all parts of your organization are aligned towards the goal of making your system reliable enough. SLOs provide a common language and shared understanding between different parts of your organization, anchoring the reliability conversation on concrete data. It's tempting to consider SLOs to be solely an operational concern, but for them to function correctly as a prioritization signal, the target must be set in conjunction with engineering and product teams. Everyone must agree that the target accurately represents the desired experience of your users.

## How SLOs help you build features faster
> The primary goal for most development organizations is to design and build product features, ideally as quickly as possible. The problem with building new features quickly is that there's often a strong negative correlation between development velocity and system reliability. It's all too common for a reliability deficit caused by the focus on features to be noticed only when it causes widespread complaints via social media, support forums, and then dealt with reactively in great haste. A missed reliability target signals when too many things users care about have been broken by excessive development velocity. The main question SLO's can help development teams answer is, when moving fast and breaking things, how fast is too fast? Or alternatively, how do you balance the risk to reliability from changing a system with the requirement to build new cool features for that system. Measuring SLO performance gives a real-time indication of the reliability cost of new features. If everyone agrees the SLO represents the point at which you are no longer meeting the expectations of your users, then broadly speaking, being well within SLO is a signal that you can move faster without causing those users pain. Conversely, burning most or, in the worst cases, multiples of your error budget, means you have to lift your foot off the accelerator. You can plan proactively by estimating risks to your reliability from the roll-out of new features in terms of time to detection, time to resolution, and impact percentage. This allows you to gauge the potential amount of error budget that each risk might consume. If you can afford to pay the reliability cost of a specific risk from your budget, you don't have to spend engineering effort mitigating or eliminating that risk.

# SLOs vs SLAs
- Service Level Aggrements: Aggrements with customers about the reliability of your service
- Service Level Objects: Thresholds that catch an issue before it breaches your SLA
 So to sum up, an SLA is a external promise that comes with consequences, often monetary. While an SLO is effectively an internal promise to meet customer expectations. 
 > So what do you want to promise your customers? After all, deciding how reliable you want your service to be depends on what your customers expect. For example, do you want to promise that every HTTP request a customer makes on your service returns a response in 300 milliseconds or less? In general, the minimum it takes for a customer to not be repelled by your service is a good starting point. If your SLA says that, for every request your customer makes, they'll get a response in 300 milliseconds, then perhaps your SLO, you'll want to say that the response will be returned in 200 milliseconds, instead. What about the consequences of violating your SLA? What do you think the equivalent consequence should be when you breach the promise to meet those customer expectations? You'll learn how to decide this information throughout these lessons. But just keep in mind that when you do violate your SLOs, it suddenly becomes really important to no longer have more outages. So you'll want to take steps to remove risks from your service. That means slowing down the rate of change to the system and eliminating risks. Either by doing fewer pushes, devoting engineering and automation efforts to reducing and eliminating areas of risks, etc.
 ## The happiness test
 > let's talk about exactly what you're promising. What do you think of when you hear the word reliable in the context of a service? Take a minute to think about other services like Netflix, Twitter, Google Search, etc. How do you tell if these services are working? Maybe you're thinking that Google Search is working when you type a search query and you get a page of relevant results. Or when you click on a title in Netflix, you get the right picture and sound. Or perhaps when you order a Lyft, the route it takes to get you home is relatively efficient. There are many characteristics of reliable services. But the common theme is that users perceive a service to be unreliable when it fails to meet their expectations, whatever those may be. Users whose expectations have not been met tend to get grumpy. So we think a good rule of thumb to help you set SLO targets is what we call the happiness test. The test states that services need target SLOs that capture the performance and availability levels that if barely met would keep a typical customer happy. Simply put, if your service is performing exactly at its target SLOs, your average user would be happy with that performance. If it were any less reliable, you'd no longer be meeting their expectations and they would become unhappy. If your service meets target SLO, that means you have happy customers. If it misses the target SLO, that means you have sad customers. We'll learn more about target SLOs in an upcoming lesson. The challenge is quantifying and measuring the happiness of your customers since you can't do this directly. It's bad if customers are unhappy despite the fact that you appear to be meeting all of your SLOs. You have to be able to make sure you're thinking about all groups of your customers. What people are using mobile apps versus folks with a desktop browser, or those in a completely different continent or market all together. The impact of an outage may not be spread out equally, but SLOs are generally aggregates across your user base. If one customer is getting all of your error budget, they will probably not be happy. To help you get more hands-on experience with thinking about working services, we've created a short assessment at the end of this lesson to come up with more reliability characteristics.
 
